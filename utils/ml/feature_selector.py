"""
Feature Selection - Otomatik Feature SeÃ§imi
En Ã¶nemli feature'larÄ± seÃ§er, gereksizleri kaldÄ±rÄ±r
"""

import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.ensemble import RandomForestClassifier
import logging

logger = logging.getLogger(__name__)


class FeatureSelector:
    """Otomatik feature selection"""
    
    def __init__(self):
        self.selected_features = None
        self.feature_scores = None
    
    def select_by_variance(self, df, threshold=0.01):
        """
        DÃ¼ÅŸÃ¼k varyans feature'larÄ± kaldÄ±r
        Args:
            df: Feature DataFrame
            threshold: Minimum varyans eÅŸiÄŸi
        Returns: SeÃ§ilen feature listesi
        """
        try:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            # Varyans hesapla
            variances = df[numeric_cols].var()
            
            # DÃ¼ÅŸÃ¼k varyans feature'larÄ± kaldÄ±r
            selected = variances[variances > threshold].index.tolist()
            
            removed = len(numeric_cols) - len(selected)
            logger.info(f"ðŸ“Š Variance selection: {len(selected)} seÃ§ildi, {removed} kaldÄ±rÄ±ldÄ±")
            
            return selected
            
        except Exception as e:
            logger.error(f"Variance selection hatasÄ±: {str(e)}")
            return list(df.columns)
    
    def select_by_correlation(self, df, threshold=0.9):
        """
        YÃ¼ksek korelasyonlu feature'larÄ± kaldÄ±r
        Args:
            df: Feature DataFrame
            threshold: Korelasyon eÅŸiÄŸi (>threshold olanlar kaldÄ±rÄ±lÄ±r)
        Returns: SeÃ§ilen feature listesi
        """
        try:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            # Korelasyon matrisi
            corr_matrix = df[numeric_cols].corr().abs()
            
            # Ãœst Ã¼Ã§gen
            upper = corr_matrix.where(
                np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
            )
            
            # YÃ¼ksek korelasyonlu feature'larÄ± bul
            to_drop = [column for column in upper.columns if any(upper[column] > threshold)]
            
            selected = [col for col in numeric_cols if col not in to_drop]
            
            logger.info(f"ðŸ“Š Correlation selection: {len(selected)} seÃ§ildi, {len(to_drop)} kaldÄ±rÄ±ldÄ±")
            
            return selected
            
        except Exception as e:
            logger.error(f"Correlation selection hatasÄ±: {str(e)}")
            return list(df.columns)
    
    def select_k_best(self, X, y, k=10):
        """
        En iyi K feature'Ä± seÃ§ (supervised)
        Args:
            X: Feature matrix
            y: Target labels
            k: SeÃ§ilecek feature sayÄ±sÄ±
        Returns: SeÃ§ilen feature indeksleri
        """
        try:
            selector = SelectKBest(score_func=f_classif, k=min(k, X.shape[1]))
            selector.fit(X, y)
            
            # Skorlar
            scores = selector.scores_
            selected_indices = selector.get_support(indices=True)
            
            self.feature_scores = scores
            
            logger.info(f"ðŸ“Š SelectKBest: {len(selected_indices)} feature seÃ§ildi")
            
            return selected_indices
            
        except Exception as e:
            logger.error(f"SelectKBest hatasÄ±: {str(e)}")
            return np.arange(X.shape[1])
    
    def select_by_importance(self, X, y, threshold=0.01):
        """
        Random Forest feature importance ile seÃ§
        Args:
            X: Feature matrix
            y: Target labels
            threshold: Minimum importance eÅŸiÄŸi
        Returns: SeÃ§ilen feature indeksleri
        """
        try:
            # Random Forest ile importance hesapla
            rf = RandomForestClassifier(n_estimators=100, random_state=42)
            rf.fit(X, y)
            
            importances = rf.feature_importances_
            
            # Threshold Ã¼stÃ¼ feature'lar
            selected_indices = np.where(importances > threshold)[0]
            
            self.feature_scores = importances
            
            logger.info(f"ðŸ“Š Feature importance: {len(selected_indices)} feature seÃ§ildi")
            
            return selected_indices
            
        except Exception as e:
            logger.error(f"Feature importance hatasÄ±: {str(e)}")
            return np.arange(X.shape[1])
    
    def auto_select(self, df, method='all'):
        """
        Otomatik feature selection (tÃ¼m yÃ¶ntemler)
        Args:
            df: Feature DataFrame
            method: 'variance', 'correlation', 'all'
        Returns: SeÃ§ilen feature listesi
        """
        try:
            selected = list(df.columns)
            
            if method in ['variance', 'all']:
                selected = self.select_by_variance(df)
                df = df[selected]
            
            if method in ['correlation', 'all']:
                selected = self.select_by_correlation(df)
                df = df[selected]
            
            logger.info(f"âœ… Auto selection: {len(selected)} feature seÃ§ildi")
            self.selected_features = selected
            
            return selected
            
        except Exception as e:
            logger.error(f"Auto selection hatasÄ±: {str(e)}")
            return list(df.columns)
    
    def get_feature_ranking(self):
        """Feature ranking'i dÃ¶ndÃ¼r"""
        if self.feature_scores is None:
            return None
        
        ranking = pd.DataFrame({
            'feature_index': range(len(self.feature_scores)),
            'score': self.feature_scores
        }).sort_values('score', ascending=False)
        
        return ranking


# KullanÄ±m Ã¶rneÄŸi
def select_best_features(df, method='all'):
    """En iyi feature'larÄ± seÃ§"""
    try:
        selector = FeatureSelector()
        selected = selector.auto_select(df, method=method)
        
        logger.info(f"âœ… {len(selected)} feature seÃ§ildi: {selected[:10]}...")
        
        return selected
        
    except Exception as e:
        logger.error(f"Feature selection hatasÄ±: {str(e)}")
        return list(df.columns)
